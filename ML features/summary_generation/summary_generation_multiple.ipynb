{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import langchain \n",
    "from torch import cuda, bfloat16\n",
    "from fpdf import FPDF\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from time import time\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.document_loaders import TextLoader,PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import MapReduceDocumentsChain, ReduceDocumentsChain,ConversationalRetrievalChain,StuffDocumentsChain\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.llms import CTransformers\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain import PromptTemplate, LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading downloaded llm suitable for local usage,temperature(entropy/randomness in answer):1e-2\n",
    "llm = CTransformers(model=r\"C:\\Users\\Medha\\miniconda3\\m3_topic_summ\\models\\llama-2-7b-chat.ggmlv3.q2_K.bin\", model_type=\"llama\", streaming=True, \n",
    "                    callbacks=[StreamingStdOutCallbackHandler()],\n",
    "                    config={'max_new_tokens':4096,'temperature':0.01, 'context_length':4096})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the pdf files from the path\n",
    "loader = PyPDFLoader(r'C:\\Users\\Medha\\miniconda3\\m3_topic_summ\\data\\lec4\\lec4_transcript.pdf')\n",
    "docs = loader.load()  \n",
    "\n",
    "# #load the pdf files from the path\n",
    "# loader = DirectoryLoader(r'C:\\Users\\Medha\\miniconda3\\m3_topic_summ\\data\\textbooks_extra_materials',glob=\"*.pdf\",loader_cls=PyPDFLoader)\n",
    "# docs = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def summary_generation(file_path):\n",
    "    # Map\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    docs = loader.load() \n",
    "    map_template = \"\"\"The following is a set of documents\n",
    "    {docs}\n",
    "    Based on this list of docs, please identify the main themes and concepts\n",
    "    Expand the description of each topic and concept for 2-3 lines that should include its basic descriptions,key points and formulas if any.\n",
    "    Helpful Answer:\"\"\"\n",
    "    map_prompt = PromptTemplate.from_template(map_template)\n",
    "    map_chain = LLMChain(llm=llm, prompt=map_prompt)\n",
    "    # Reduce\n",
    "    reduce_template = \"\"\"The following is set of summaries:\n",
    "    {docs}\n",
    "    Take these and distill it into a final, consolidated summary of the main topics and concepts that should include definitions and formulas of the concepts.Mention all the key points and formulas related to a concept. \n",
    "    Expand the description of each topic and concept for 2-3 lines.\n",
    "    Helpful Answer:\"\"\"\n",
    "    reduce_prompt = PromptTemplate.from_template(reduce_template)\n",
    "        # Run chain\n",
    "    reduce_chain = LLMChain(llm=llm, prompt=reduce_prompt)\n",
    "\n",
    "    # Takes a list of documents, combines them into a single string, and passes this to an LLMChain\n",
    "    combine_documents_chain = StuffDocumentsChain(\n",
    "        llm_chain=reduce_chain, document_variable_name=\"docs\"\n",
    "    )\n",
    "\n",
    "    # Combines and iteravely reduces the mapped documents\n",
    "    reduce_documents_chain = ReduceDocumentsChain(\n",
    "        # This is final chain that is called.\n",
    "        combine_documents_chain=combine_documents_chain,\n",
    "        # If documents exceed context for `StuffDocumentsChain`\n",
    "        collapse_documents_chain=combine_documents_chain,\n",
    "        # The maximum number of tokens to group documents into.\n",
    "        token_max=4000,\n",
    "    )\n",
    "        # Combining documents by mapping a chain over them, then combining results\n",
    "    map_reduce_chain = MapReduceDocumentsChain(\n",
    "        # Map chain\n",
    "        llm_chain=map_chain,\n",
    "        # Reduce chain\n",
    "        reduce_documents_chain=reduce_documents_chain,\n",
    "        # The variable name in the llm_chain to put the documents in\n",
    "        document_variable_name=\"docs\",\n",
    "        # Return the results of the map steps in the output\n",
    "        return_intermediate_steps=False,\n",
    "    )\n",
    "\n",
    "    text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=500, chunk_overlap=50\n",
    "    )\n",
    "    split_docs = text_splitter.split_documents(docs)\n",
    "    all_summaries=map_reduce_chain.run(split_docs)\n",
    "    print(all_summaries)\n",
    "    \n",
    "    return all_summaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_paragraph_to_pdf(para,folder_name,file_name):\n",
    "    # Paragraph to convert\n",
    "    paragraph = para\n",
    "    # Folder path to store the PDF\n",
    "    folder_path = folder_name # Replace with your actual folder path\n",
    "    # Desired PDF filename\n",
    "    pdf_name = file_name+\".pdf\"  # Replace with your desired filename\n",
    "    # Create a PDF object\n",
    "    pdf = FPDF()\n",
    "    # Add a page\n",
    "    pdf.add_page()\n",
    "\n",
    "    # Set font and font size\n",
    "    pdf.set_font(\"Arial\", size=12)\n",
    "    # Write the paragraph to the PDF\n",
    "    pdf.write(5, paragraph)\n",
    "    # Save the PDF to the specified folder and filename\n",
    "    pdf.output(f\"{folder_path}/{pdf_name}\", \"F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all=summary_generation(r'C:\\Users\\Medha\\miniconda3\\m3_topic_summ\\data\\lec4\\lec4_transcript.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_paragraph_text(text):\n",
    "    # Open a text file for writing\n",
    "    with open(\"summary.txt\", \"w\") as file:\n",
    "    # Write the model output paragraph to the file\n",
    "        file.write(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
